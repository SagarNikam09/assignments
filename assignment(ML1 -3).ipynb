{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b393df49",
   "metadata": {},
   "source": [
    "Q1]\n",
    "**Filter Method**\n",
    "\n",
    "The Filter method is a feature selection method that evaluates features based on their statistical properties, such as correlation with the target variable, information gain, or chi-squared. It is a **model-agnostic** method, meaning that it can be used with any machine learning algorithm. Filter methods are typically computationally efficient and easy to implement.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "1. Calculate a statistical score for each feature.\n",
    "2. Select the features with the highest scores.\n",
    "\n",
    "**Common filter methods:**\n",
    "\n",
    "* Correlation coefficient\n",
    "* Information gain\n",
    "* Chi-squared test\n",
    "* Variance thresholding\n",
    "* SelectKBest\n",
    "\n",
    "Q2]\n",
    "**Wrapper Method**\n",
    "\n",
    "The Wrapper method is a feature selection method that evaluates features based on their performance in a machine learning model. It is a **model-dependent** method, meaning that it must be used with a specific machine learning algorithm. Wrapper methods are typically more computationally expensive than filter methods, but they can often produce better results.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "1. Train a machine learning model on a subset of features.\n",
    "2. Evaluate the model's performance.\n",
    "3. Add or remove features from the subset and repeat steps 1 and 2.\n",
    "4. Select the subset of features that produces the best model performance.\n",
    "\n",
    "**Common wrapper methods:**\n",
    "\n",
    "* Forward selection\n",
    "* Backward elimination\n",
    "* Recursive feature elimination\n",
    "\n",
    "Q3]\n",
    "**Embedded Method**\n",
    "\n",
    "The Embedded method is a feature selection method that is embedded within a machine learning algorithm. It selects features while the model is being trained. Embedded methods are typically model-dependent and computationally efficient.\n",
    "\n",
    "**Common embedded methods:**\n",
    "\n",
    "* LASSO\n",
    "* Ridge regression\n",
    "* Tree-based models (e.g., random forests, gradient boosting trees)\n",
    "\n",
    "Q4]\n",
    "**Drawbacks of the Filter Method**\n",
    "\n",
    "* Filter methods are model-agnostic, which means that they cannot take into account the specific relationships between features and the target variable that are learned by a machine learning model.\n",
    "* Filter methods can be sensitive to outliers and noise in the data.\n",
    "\n",
    "Q5]\n",
    "**When to use the Filter Method**\n",
    "\n",
    "* When you have a large number of features and need to quickly reduce the dimensionality of the data.\n",
    "* When you are unsure of which features to include in the model.\n",
    "* When you want to use a model-agnostic feature selection method.\n",
    "\n",
    "Q6]\n",
    "**using the Filter Method to select features for a customer churn prediction model**\n",
    "\n",
    "1. Load the dataset and split it into training and test sets.\n",
    "2. Calculate a statistical score for each feature, such as the correlation coefficient or information gain.\n",
    "3. Select the features with the highest scores.\n",
    "4. Train a machine learning model on the selected features and evaluate its performance on the test set.\n",
    "5. If the model's performance is not satisfactory, you can adjust the number of features selected or try a different statistical score.\n",
    "\n",
    "Q7]\n",
    "**using the Embedded Method to select features for a soccer match outcome prediction model**\n",
    "\n",
    "1. Load the dataset and split it into training and test sets.\n",
    "2. Train a tree-based machine learning model, such as a random forest or gradient boosting tree, on the training set.\n",
    "3. The model will automatically select the most relevant features during training.\n",
    "4. Evaluate the model's performance on the test set.\n",
    "5. If the model's performance is not satisfactory, you can adjust the hyperparameters of the model or try a different embedded method\n",
    "\n",
    "\n",
    "Q8]\n",
    "**using the Wrapper Method to select features for a house price prediction model**\n",
    "\n",
    "1. Load the dataset and split it into training and test sets.\n",
    "2. Create a subset of features.\n",
    "3. Train a machine learning model on the subset of features and evaluate its performance on the test set.\n",
    "4. Add or remove features from the subset and repeat steps 2 and 3.\n",
    "5. Select the subset of features that produces the best model performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad31232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
